---
title: "Final Proposal"
author: "Dev Desai, Thanh Mai, Shobhit Sarkar, Brian Xicon"
output: html_document
date: "2023-11-13"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
install.packages("ggmap")
library(ggmap)
```

# Description:
The dataset we are using is a list of all active businesses from the City of Los Angeles. The fields include the account number, business name, DBA name, street address, city, zip code, location description, mailing address, mailing city, mailing zip code, primary NAICS description (what the company does), NAICS (code of what the company does), council district, location start date, location end date, and lastly the actual location as coordinates. It has more than 580000 companies in this dataset. We got this dataset from [https://catalog.data.gov/dataset/listing-of-active-businesses]

```{r, cache=TRUE}
# Download the csv from the source, if not already on disk.
# The file is 125 MB, which might take up to a minute to download.

if (!file.exists("Listing_of_Active_Businesses.csv")) {
  # URL is a CDN link, which is served by https://catalog.data.gov/dataset/listing-of-active-businesses
  url <- "https://data.lacity.org/api/views/6rrh-rzua/rows.csv?accessType=DOWNLOAD"
  download.file(url, "Listing_of_Active_Businesses.csv", mode = "wb")
}
businesses <- read.csv("Listing_of_Active_Businesses.csv")
head(businesses)
cat("Number of rows in data: ", nrow(businesses), ". Expected 582k rows", sep="")

zips <- read.csv("uszips.csv")
head(zips)
```


# Data Cleaning Steps:
```{r}
# Converting dates to Date objects
businesses$LOCATION.START.DATE <- as.Date(businesses$LOCATION.START.DATE, format = "%m/%d/%Y")
businesses$LOCATION.END.DATE <- as.Date(businesses$LOCATION.END.DATE, format = "%m/%d/%Y")

# Removing duplicate rows
businesses <- businesses %>% distinct()

#Converting PRIMARY.NAICS.DESCRIPTION to Factor
businesses$PRIMARY.NAICS.DESCRIPTION <- as.factor(businesses$PRIMARY.NAICS.DESCRIPTION)

#Split Up Location to Longitude & Latitude
businesses <- businesses %>%
  separate(`LOCATION`,
           into = c("Latitude", "Longitude"),
           sep = ', ') %>%
  mutate(Latitude = parse_number(Latitude),
         Longitude = parse_number(Longitude))

#Filters to just the Continental U.S.
businesses <- businesses %>%
  filter(
    Latitude >= 24.396308 & Latitude <= 49.384358,
    Longitude >= -125.001650 & Longitude <= -66.934570
  )

head(businesses)
```

# Marginal Summaries:
```{r}
# Some basic numerical marginal summaries
numeric_summaries <- businesses %>%
  summarise(
    StartDateEarliest = min(LOCATION.START.DATE, na.rm = TRUE),
    StartDateLatest = max(LOCATION.START.DATE, na.rm = TRUE),
  )
numeric_summaries
```

```{r}
# Some basic categorical marginal summaries
categorical_summaries <- businesses %>%
  filter(!is.na(PRIMARY.NAICS.DESCRIPTION) & PRIMARY.NAICS.DESCRIPTION != "") %>%
  summarise(
    MostCommonCity = names(which.max(table(CITY))),
    MostCommonNAICS = names(which.max(table(PRIMARY.NAICS.DESCRIPTION)))
  )

categorical_summaries
```

# Exploration plan:
## Potential research questions:
1. What types of businesses are more common? Is there a trend over time?


```{r}
library(ggplot2)
library(dplyr)
library(readr)
library(lubridate)


# Convert the 'LOCATION.START.DATE' to a Date object and extract the year
business_data <- business_data %>%
  mutate(Year = year(as.Date(LOCATION.START.DATE, format = "%m/%d/%Y"))) %>%
  filter(Year >= 2000) %>%
  filter(!is.na(PRIMARY.NAICS.DESCRIPTION))

# Count the number of each type of business by year
business_trends <- business_data %>%
  group_by(Year, Business_Type = PRIMARY.NAICS.DESCRIPTION) %>%
  summarise(Count = n(), .groups = 'drop') %>%
  ungroup() %>%
  arrange(Year)

# Select the top 10 business types based on total count and convert to factor
top_business_types <- business_trends %>%
  group_by(Business_Type) %>%
  summarise(Total_Count = sum(Count), .groups = 'drop') %>%
  arrange(desc(Total_Count)) %>%
  slice(2:11) %>%  
  pull(Business_Type)  
business_trends$Business_Type <- factor(business_trends$Business_Type, levels = top_business_types)

# Filter the trends data to only include the top 10 business types
filtered_trends <- business_trends %>%
  filter(Business_Type %in% top_business_types)

# Create a line plot with colors for different business types
library(ggplot2)


plot <- ggplot(filtered_trends, aes(x = Year, y = Count, color = Business_Type)) +
  geom_line() + # Use geom_line for line charts
  labs(title = "Trend of Top 10 Business Types Since 2000",
       x = "Year",
       y = "Number of Businesses") +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1, size = 8), # 
    legend.position = "right", 
    legend.text = element_text(size = 6), 
    legend.title = element_text(size = 8),
    legend.key.size = unit(0.5, "cm"),
    legend.margin = margin(t = 0, r = 0, b = 0, l = 0), 
    plot.margin = margin(t = 1, r = 1, b = 1, l = 1, unit = "cm") 
  ) +
  guides(color = guide_legend(title = "Business Type")) 

print(plot)

```
**About the graph:**
a. As we can see from the graph, there is a peak in all the different businesses around the year 2015 which might be an indication of a flourishing economy. 
b. However, after the year 2015, there is a sharp decline in the number of businesses which might indicate a bad economic situation or a saturation of industries (or the COVID -19 pandemic).
c. Janitorial services shows the most steady behaviour while the most volatility is shown by the industries in all other personal services. 

Note: I decided to include the data from the year 2000 and only of the top 10 industries. Or else, the graph seems to be very difficult to read and understand. 

2. Are there any time periods with more or less active businesses? Why?
3. Can we integrate geographic data into the dataset? Do businesses gravitate towards certain regions? Why?
4. How is the distribution of different business types evolving over time within each council district? Are new industries emerging in specific districts?
5. Are there seasonal or annual trends in the number of new business registrations, and can these be linked to economic cycles or local events?
## Steps:
- Do data cleaning, especially on the NAICS code and description (business type/industry).
- Plot various variables across time, both linearly and seasonally.
- Find additional economic data (either nationally or locally), and find correlations.
- Get additional geographic data around the Los Angeles metropolitan area, for instance, population distribution by district.
- Plot the distribution of businesses on a map, perhaps also create a choropleth (if only district data) or heatmap (if more granular data is available) to show tendencies in distribution.
- Find correlations between variables in the district data and what types of businesses are more active in those areas.
- For any given correlation that is of research interest, can we predict business activity using that given set of variables? Try predictions using both regression methods and machine learning techniques.
- Does our prediction/hypothesis make sense? Can we prove it, perhaps by looking at other areas or on a nation-wide scale?

```{r}
# Sample 1000 random businesses to reduce computation time.
# Use during development, but switch back to the full dataset when done.
businesses_trunc <- head(businesses, 1000)
```

### Can we integrate geographic data into the dataset? Do businesses gravitate towards certain regions? Why? (Brian Xicon)
```{r}
#Adds simplified ZIP code to be used with the zips dataset.
businesses <- businesses %>% 
  mutate(ZIP_CODE_SHORT = str_split(ZIP.CODE, "-", simplify = TRUE)[, 1],
         ZIP_CODE_SHORT = as.integer(ZIP_CODE_SHORT))

#Selects the only columns needed to merge with businesses.
zips_simplified <- zips %>% 
  select(zip, state_name)

#Joins the zips columns to businesses
businesses <- businesses %>% 
  left_join(zips_simplified, by = c("ZIP_CODE_SHORT" = "zip"))

#head(businesses)

#Picks the valid locations
valid_locations <- businesses %>%
  filter(!is.na(Latitude) & !is.na(Longitude) & !is.na(state_name))

head(valid_locations)

state <- map_data("state")
```
# Graph of Companies in Continental United States With Color Corresponding To NAICS (Brian Xicon)
```{r}
ggplot() +
  geom_polygon(data = state, aes(x = long, y = lat, group = group), fill = NA, color = "black") + 
  geom_point(data = valid_locations, aes(x = Longitude, y = Latitude, color = PRIMARY.NAICS.DESCRIPTION), size = 1) +    
  coord_fixed(1.3) +  # Set aspect ratio
  ggtitle("Business Locations In Continental United States") +
  labs(color = "State") +
  theme(legend.position = "none")
```
# Top 10 States by Number of Businesses (According to Dataset) (Brian Xicon)
```{r}
state_business_counts <- valid_locations %>%
  group_by(state_name) %>%
  summarise(business_count = n()) %>%
  arrange(desc(business_count))

top_states <- state_business_counts %>%
  top_n(10, business_count)

top_states

ggplot(top_states, aes(x = reorder(state_name, business_count), y = business_count)) +
  geom_bar(stat = "identity") +
  xlab("State") +
  ylab("Number of Businesses") +
  ggtitle("Top 10 States by Number of Businesses") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

top_states_no_cali <- state_business_counts %>%
  filter(state_name != "California") %>%
  top_n(10, business_count)

ggplot(top_states_no_cali, aes(x = reorder(state_name, business_count), y = business_count)) +
  geom_bar(stat = "identity") +
  xlab("State") +
  ylab("Number of Businesses") +
  ggtitle("Top 10 States by Number of Businesses") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

#Since this is a California based dataset it will be easy to notice just how many more companies California has compared to the other states. The bar graph shown shows just how large of a margin it is to go from 1st place (California) to 2nd place (New York). Removing California from the bar graph we can then see the margins are much less drastic compared to the other states.
```

# Stacked Barchart Comparing NAICS As Well (Brian Xicon)
```{r}
#Count businesses by state and NAICS, excluding California
state_naics_counts <- valid_locations %>%
  filter(state_name != "California") %>%
  group_by(state_name, PRIMARY.NAICS.DESCRIPTION) %>%
  summarise(business_count = n()) %>%
  ungroup()

#Find top 10 states
top_states <- state_naics_counts %>%
  group_by(state_name) %>%
  summarise(total_business_count = sum(business_count)) %>%
  arrange(desc(total_business_count)) %>%
  top_n(10, total_business_count) %>%
  select(state_name)

#Filter for top states
top_state_naics_counts <- state_naics_counts %>%
  filter(state_name %in% top_states$state_name)

#Find top 10 NAICS descriptions
top_naics <- top_state_naics_counts %>%
  group_by(PRIMARY.NAICS.DESCRIPTION) %>%
  summarise(count = n()) %>%
  arrange(desc(count)) %>%
  top_n(10, count) %>%
  pull(PRIMARY.NAICS.DESCRIPTION)

#Filter for top NAICS descriptions
final_data <- top_state_naics_counts %>%
  filter(PRIMARY.NAICS.DESCRIPTION %in% top_naics)

#Make distinct palette
my_palette <- c("#e6194B", "#3cb44b", "#ffe119", "#4363d8", "#f58231", "#911eb4",
                "#46f0f0", "#f032e6", "#bcf60c", "#fabebe", "#008080", "#e6beff",
                "#9a6324", "#fffac8", "#800000", "#aaffc3", "#808000", "#ffd8b1",
                "#000075", "#808080", "#000000", "#ffd700", "#4b0082", "#800080")

#Plot stacked barchart
ggplot(final_data, aes(x = reorder(state_name, business_count), y = business_count, fill = PRIMARY.NAICS.DESCRIPTION)) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = my_palette, name = "NAICS Description") +
  xlab("State") +
  ylab("Number of Businesses") +
  ggtitle("Top 10 States by Number of Businesses by NAICS (Excluding California)") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "bottom")
```

